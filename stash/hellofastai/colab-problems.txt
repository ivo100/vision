
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader

# 1. Data Loading and Preprocessing
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = '/path/to/your/dataset'  # Replace with your dataset path
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}
dataloaders = {x: DataLoader(image_datasets[x], batch_size=16,
                                             shuffle=True, num_workers=4)
              for x in ['train', 'val']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# 2. Model Selection and Initialization
model = models.resnet34(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_names))  # Adjust for your number of classes
model = model.to(device)

# 3. Loss Function and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# 4. Training Loop
num_epochs = 10  # Adjust as needed

for epoch in range(num_epochs):
    print(f'Epoch {epoch}/{num_epochs - 1}')
    print('-' * 10)

    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()  # Set model to training mode
        else:
            model.eval()   # Set model to evaluate mode

        running_loss = 0.0
        running_corrects = 0

        for inputs, labels in dataloaders[phase]:
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            with torch.set_grad_enabled(phase == 'train'):
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                if phase == 'train':
                    loss.backward()
                    optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double() / dataset_sizes[phase]

        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

print('Finished Training')

====

# Install necessary libraries
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install fastai==2.7.12

# Successfully installed fastai-2.7.12 fastcore-1.5.55 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0

#     Found existing installation: fastai 2.7.18
#      Uninstalling fastai-2.7.18:
#        Successfully uninstalled fastai-2.7.18


# Import libraries
from fastai.vision.all import *

# Download MNIST dataset
path = untar_data(URLs.MNIST)

# Define data loaders
dls = ImageDataLoaders.from_folder(path, train='training', valid='testing',
                                   ds_tfms=(ToTensor(),), bs=64)

# Define model
model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(28*28*3, 128),  # Change input size to 2352
    nn.ReLU(),
    nn.Linear(128, 10)
)
# Define learner
learn = Learner(dls, model, metrics=accuracy)

# Train the model
learn.fit_one_cycle(5)

CPU

epoch	train_loss	valid_loss	accuracy	time
0	0.247082	0.218633	0.931900	01:16
1	0.123610	0.117106	0.965100	01:10
2	0.081111	0.082969	0.974900	01:11
3	0.053003	0.073332	0.977900	01:14
4	0.045486	0.072398	0.978500	01:09


# ... (previous code) ...

# Set device to CUDA if available, otherwise CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move model and data loaders to the device
learn = Learner(dls, model, metrics=accuracy).to(device)
### ERROR
learn.dls.to(device)

# Train the model
learn.fit_one_cycle(5)

# Device selection with error handling
if torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using CUDA device:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("CUDA not available, using CPU instead.")

# Define learner and move model to device
learn = Learner(dls, model, metrics=accuracy).to(device)

# Move data loaders to device with error handling
try:
    learn.dls.device = device
except Exception as e:
    print("Error moving data loaders to device:", e)
    print("Data loaders might remain on CPU.")

###

# Define data loaders and specify device
dls = ImageDataLoaders.from_folder(
    path, train='training', valid='testing',
    ds_tfms=(ToTensor(),), bs=64, device=device  # Specify device here
)

learn.fine_tune(1)
